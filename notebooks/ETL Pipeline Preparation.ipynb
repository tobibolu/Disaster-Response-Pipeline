{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ETL Pipeline Preparation\n### 1. Import libraries and load datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport sqlite3\nfrom sqlalchemy import create_engine"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "messages = pd.read_csv('messages.csv')\nmessages.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "categories = pd.read_csv('categories.csv')\ncategories.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 2. Merge datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = messages.merge(categories, how='outer', on='id')\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 3. Split categories into separate columns"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "categories = df.categories.str.split(';', expand=True)\ncategories.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Extract column names from the first row (strip trailing \"-0\"/\"-1\")\nrow = categories.iloc[0, :]\ncategory_colnames = row.apply(lambda x: x[:-2])\nprint(category_colnames)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "categories.columns = category_colnames\ncategories.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 4. Convert category values to binary (0 or 1)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "for column in categories:\n    categories[column] = categories[column].str[-1]\n    categories[column] = categories[column].astype(int)\ncategories.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 5. Replace the original categories column with the new binary columns"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = df.drop('categories', axis=1)\ndf.head()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = pd.concat([df, categories], axis=1)\ndf.head()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 6. Remove duplicates"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.duplicated().sum()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df = df.drop_duplicates()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Confirm duplicates removed\ndf.duplicated().sum()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 7. Save to SQLite database"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "engine = create_engine('sqlite:///InsertDatabaseName.db')\ndf.to_sql('ETL', engine, index=False)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}